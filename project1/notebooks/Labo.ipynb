{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts') \n",
    "\n",
    "from proj1_helpers import *         # Not necessary to copy function for loading CSV data anymore\n",
    "from preprocessing_helpers import * # All function related to preprocessing are now in this helper script \n",
    "                                    # (in the scripts-directory)\n",
    "\n",
    "\n",
    "#opther stuff to import (for testing purposes)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import sample_data, load_data, standardize\n",
    "from least_squares import least_squares\n",
    "from plots import visualization\n",
    "from classifiers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, verbose = False):\n",
    "    n_samples = y_train.shape[0]\n",
    "\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    sub_x_1 = x[indices][:int(ratio*n_samples)]\n",
    "    sub_x_2 = x[indices][int(ratio*n_samples):]\n",
    "\n",
    "    sub_y_1 = y[indices][:int(ratio*n_samples)]\n",
    "    sub_y_2 = y[indices][int(ratio*n_samples):]\n",
    "\n",
    "    if verbose:\n",
    "        print('ration:\\t', ratio)\n",
    "        print('ratio of samples 1st subset:\\t', np.round_((sub_y_1 == 1).sum()/(ratio*n_samples), decimals=2))\n",
    "        print('ratio of samples 2nd subset:\\t', np.round_((sub_y_2 == 1).sum()/((1-ratio)*n_samples), decimals=2))\n",
    "    return sub_x_1, sub_y_1, sub_x_2, sub_y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=138.62943611198904\n",
      "Current iteration=100, loss=60.247169677116474\n",
      "Current iteration=200, loss=54.698477045952146\n",
      "Current iteration=300, loss=62.96436436532191\n",
      "Current iteration=400, loss=56.388418086224235\n",
      "Current iteration=500, loss=202.12861560941403\n",
      "Current iteration=600, loss=58.30823428492711\n",
      "Current iteration=700, loss=60.95310612871522\n",
      "Current iteration=800, loss=60.47515458056051\n",
      "Current iteration=900, loss=54.89736440630447\n",
      "0.905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.905,\n",
       " 'accuracy_test': 0.905,\n",
       " 'params': {'name': 'LogisticRegression',\n",
       "  'lambda_': 1,\n",
       "  'regulairizer': 'L2',\n",
       "  'gamma': 0.1,\n",
       "  'max_iterations': 1000,\n",
       "  'threshold': 1e-08}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression demo on fake data\n",
    "clf = ClassifierLogisticRegression(\n",
    "    lambda_ = 1, \n",
    "    regularizer = 'L2', \n",
    "    gamma=0.1, \n",
    "    max_iterations = 1000, \n",
    "    threshold = 1e-8\n",
    "    )\n",
    "\n",
    "## load data.\n",
    "height, weight, gender = load_data()\n",
    "\n",
    "# build sampled x and y.\n",
    "seed = 1\n",
    "y = np.expand_dims(gender, axis=1)\n",
    "X = np.c_[height.reshape(-1), weight.reshape(-1)]\n",
    "y, X = sample_data(y, X, seed, size_samples=200)\n",
    "x, mean_x, std_x = standardize(X)\n",
    "\n",
    "#train logistic regression\n",
    "tx = np.c_[np.ones((y.shape[0], 1)), x]\n",
    "clf.train(y_train=y, tx_train=tx)\n",
    "pred = clf.predict(tx)\n",
    "y = y.ravel()\n",
    "print( (pred == y).sum()/ y.shape[0] )\n",
    "clf.get_params_and_results(tx, tx, y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real stuff now\n",
    "\n",
    "TRAIN = '../data/train.csv' # due to directory structure, the data directory is now one directory above this one\n",
    "TEST = '../data/test.csv'\n",
    "y, x, ids_train = load_csv_data('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanToMean\n",
      "Sanity check :n =  250000 D =  30\n",
      "accuracy_test 0.74\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanToMedian\n",
      "Sanity check :n =  250000 D =  30\n",
      "accuracy_test 0.74\n",
      "regularization None \n",
      "\n",
      "\n",
      "RemoveNan\n",
      "Sanity check :n =  68114 D =  30\n",
      "accuracy_test 0.72\n",
      "regularization None \n",
      "\n",
      "\n",
      "RemoveNanFeatures\n",
      "Sanity check :n =  250000 D =  19\n",
      "accuracy_test 0.72\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanTo0\n",
      "Sanity check :n =  250000 D =  30\n",
      "accuracy_test 0.74\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanToMean\n",
      "Sanity check :n =  250000 D =  30\n",
      "accuracy_test 0.74\n",
      "regularization L2 \n",
      "\n",
      "\n",
      "NanToMedian\n",
      "Sanity check :n =  250000 D =  30\n",
      "accuracy_test 0.74\n",
      "regularization L2 \n",
      "\n",
      "\n",
      "RemoveNan\n",
      "Sanity check :n =  68114 D =  30\n",
      "accuracy_test 0.72\n",
      "regularization L2 \n",
      "\n",
      "\n",
      "RemoveNanFeatures\n",
      "Sanity check :n =  250000 D =  19\n",
      "accuracy_test 0.73\n",
      "regularization L2 \n",
      "\n",
      "\n",
      "NanTo0\n",
      "Sanity check :n =  250000 D =  30\n",
      "accuracy_test 0.74\n",
      "regularization L2 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check what's the best way to deal wit NaNs with a simple regression\n",
    "\n",
    "#define the possible strategies to deal with nans\n",
    "strategies = [\n",
    "    'NanToMean',        #replaces NaNs with the mean\n",
    "    'NanToMedian',      #replaces the NaNs with the median\n",
    "    'RemoveNan',        #removes the rows containing the NaNs\n",
    "    'RemoveNanFeatures', #removes the columns with NaNs\n",
    "    'NanTo0',           #replaces the NaNs with 0\n",
    "]\n",
    "\n",
    "regularization = [None, 'L2']\n",
    "for reg in regularization:\n",
    "    for strat in strategies:\n",
    "        print(strat)\n",
    "        clf = ClassifierLinearRegression(lambda_ = 0.2, regularizer = reg)\n",
    "        y_train, tx_train = preprocessing(y, x, strat, standardize=False) \n",
    "        print('Sanity check :n = ', tx_train.shape[0], 'D = ', tx_train.shape[1])\n",
    "        tx_train, y_train, tx_validation, y_validation = split_data(tx_train, y_train, ratio = 0.7, verbose = False)\n",
    "        clf.train(y_train, tx_train)\n",
    "        dictionary = clf.get_params_and_results(tx_train, tx_validation, y_train, y_validation)\n",
    "        print('accuracy_test', np.round(dictionary['accuracy_test'], decimals = 2))\n",
    "        print('regularization', clf.regularizer, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the centroid classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanToMean\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=41.33813105217429\n",
      "Current iteration=200, loss=36.437793585483455\n",
      "Current iteration=300, loss=34.84542135520159\n",
      "Current iteration=400, loss=34.13521110541265\n",
      "Current iteration=500, loss=33.768140259306186\n",
      "Current iteration=600, loss=33.56157152166979\n",
      "Current iteration=700, loss=33.43876662571297\n",
      "Current iteration=800, loss=33.36293908666624\n",
      "Current iteration=900, loss=33.31481791769768\n",
      "accuracy_test 0.92\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanToMedian\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=44.14034811311781\n",
      "Current iteration=200, loss=38.91498206812396\n",
      "Current iteration=300, loss=37.14712427387821\n",
      "Current iteration=400, loss=36.33245127858737\n",
      "Current iteration=500, loss=35.898550881524656\n",
      "Current iteration=600, loss=35.64720874553516\n",
      "Current iteration=700, loss=35.49346666637693\n",
      "Current iteration=800, loss=35.395798226993044\n",
      "Current iteration=900, loss=35.332019169635615\n",
      "accuracy_test 0.95\n",
      "regularization None \n",
      "\n",
      "\n",
      "RemoveNan\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=46.09043421045128\n",
      "Current iteration=200, loss=41.4165608540401\n",
      "Current iteration=300, loss=39.947339957299825\n",
      "Current iteration=400, loss=39.316194486981985\n",
      "Current iteration=500, loss=39.00272509934592\n",
      "Current iteration=600, loss=38.833528297378905\n",
      "Current iteration=700, loss=38.737216000844036\n",
      "Current iteration=800, loss=38.68036478839147\n",
      "Current iteration=900, loss=38.645925964577245\n",
      "accuracy_test 0.97\n",
      "regularization None \n",
      "\n",
      "\n",
      "RemoveNanFeatures\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=44.699802050211716\n",
      "Current iteration=200, loss=40.087917724227935\n",
      "Current iteration=300, loss=38.58448388808233\n",
      "Current iteration=400, loss=37.91398724986809\n",
      "Current iteration=500, loss=37.56832019203679\n",
      "Current iteration=600, loss=37.37462728690251\n",
      "Current iteration=700, loss=37.26011605439788\n",
      "Current iteration=800, loss=37.189871353400235\n",
      "Current iteration=900, loss=37.14561916988106\n",
      "accuracy_test 0.93\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanTo0\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=39.8106743964081\n",
      "Current iteration=200, loss=34.542755250010494\n",
      "Current iteration=300, loss=32.77673251494659\n",
      "Current iteration=400, loss=31.96369059930133\n",
      "Current iteration=500, loss=31.52955285004111\n",
      "Current iteration=600, loss=31.27691238853198\n",
      "Current iteration=700, loss=31.121447246323036\n",
      "Current iteration=800, loss=31.021988852672074\n",
      "Current iteration=900, loss=30.956531335851015\n",
      "accuracy_test 0.88\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanToMean\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=44.88909856279284\n",
      "Current iteration=200, loss=40.18045399895102\n",
      "Current iteration=300, loss=38.64909114365712\n",
      "Current iteration=400, loss=37.9719857145408\n",
      "Current iteration=500, loss=37.62666145167915\n",
      "Current iteration=600, loss=37.43546950852266\n",
      "Current iteration=700, loss=37.32387834580774\n",
      "Current iteration=800, loss=37.256342087013806\n",
      "Current iteration=900, loss=37.21438942129753\n",
      "accuracy_test 0.95\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanToMedian\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=43.254663518706685\n",
      "Current iteration=200, loss=38.5883164669432\n",
      "Current iteration=300, loss=37.088326820829145\n",
      "Current iteration=400, loss=36.429632858661215\n",
      "Current iteration=500, loss=36.09534554588326\n",
      "Current iteration=600, loss=35.910989543629476\n",
      "Current iteration=700, loss=35.80374984338329\n",
      "Current iteration=800, loss=35.73904335558865\n",
      "Current iteration=900, loss=35.698961516262145\n",
      "accuracy_test 0.93\n",
      "regularization None \n",
      "\n",
      "\n",
      "RemoveNan\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=41.47716605483868\n",
      "Current iteration=200, loss=36.330836124974496\n",
      "Current iteration=300, loss=34.64452687215204\n",
      "Current iteration=400, loss=33.89213776147442\n",
      "Current iteration=500, loss=33.504149159930314\n",
      "Current iteration=600, loss=33.28660517295985\n",
      "Current iteration=700, loss=33.157861118879765\n",
      "Current iteration=800, loss=33.078776636742674\n",
      "Current iteration=900, loss=33.028872094440636\n",
      "accuracy_test 0.85\n",
      "regularization None \n",
      "\n",
      "\n",
      "RemoveNanFeatures\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=43.274260799855355\n",
      "Current iteration=200, loss=38.74154221593661\n",
      "Current iteration=300, loss=37.301827815220754\n",
      "Current iteration=400, loss=36.675043882390824\n",
      "Current iteration=500, loss=36.35959766422265\n",
      "Current iteration=600, loss=36.187122199660756\n",
      "Current iteration=700, loss=36.08768874611959\n",
      "Current iteration=800, loss=36.028250310208726\n",
      "Current iteration=900, loss=35.99178734340619\n",
      "accuracy_test 0.92\n",
      "regularization None \n",
      "\n",
      "\n",
      "NanTo0\n",
      "Sanity check :n =  200 D =  2\n",
      "Current iteration=0, loss=97.04060527839235\n",
      "Current iteration=100, loss=44.37769770812987\n",
      "Current iteration=200, loss=39.311081484949185\n",
      "Current iteration=300, loss=37.63139994106449\n",
      "Current iteration=400, loss=36.87162767195244\n",
      "Current iteration=500, loss=36.474033597759075\n",
      "Current iteration=600, loss=36.247640811538936\n",
      "Current iteration=700, loss=36.111494929440056\n",
      "Current iteration=800, loss=36.02646505960272\n",
      "Current iteration=900, loss=35.971883453084416\n",
      "accuracy_test 0.93\n",
      "regularization None \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ClassifierLogisticRegression(\n",
    "    lambda_ = 0, \n",
    "    regularizer = None, \n",
    "    gamma=0.01, \n",
    "    max_iterations = 1000, \n",
    "    threshold = 1e-8\n",
    "    )\n",
    "\n",
    "for reg in regularization:\n",
    "    for strat in strategies:\n",
    "        print(strat)\n",
    "        #clf = ClassifierLinearRegression(lambda_ = 0.2, regularizer = reg)\n",
    "        y_train, tx_train = preprocessing(y, x, strat, standardize=False) \n",
    "        print('Sanity check :n = ', tx_train.shape[0], 'D = ', tx_train.shape[1])\n",
    "        tx_train, y_train, tx_validation, y_validation = split_data(tx_train, y_train, ratio = 0.7, verbose = False)\n",
    "        clf.train(y_train, tx_train)\n",
    "        dictionary = clf.get_params_and_results(tx_train, tx_validation, y_train, y_validation)\n",
    "        print('accuracy_test', np.round(dictionary['accuracy_test'], decimals = 2))\n",
    "        print('regularization', clf.regularizer, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.9285714285714286,\n",
       " 'accuracy_test': 0.85,\n",
       " 'params': {'name': 'ClassifierCentroids'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, tx_train = preprocessing(y, x, 'RemoveNanFeatures', standardize=False) \n",
    "tx_train, y_train, tx_validation, y_validation = split_data(tx_train, y_train, ratio = 0.7, verbose = False)\n",
    "y_train.shape, tx_train.shape\n",
    "\n",
    "clf = ClassifierCentroids()\n",
    "clf.train(tx_train, y_train)\n",
    "clf.get_params_and_results(tx_train, tx_validation, y_train, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.4928571428571429,\n",
       " 'accuracy_test': 0.48333333333333334,\n",
       " 'params': {'name': 'ClassifierCentroids'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, tx_train = preprocessing(y, x, 'OnlyNanFeatures', standardize=False) \n",
    "tx_train, y_train, tx_validation, y_validation = split_data(tx_train, y_train, ratio = 0.7, verbose = False)\n",
    "y_train.shape, tx_train.shape\n",
    "\n",
    "clf = ClassifierCentroids()\n",
    "clf.train(tx_train, y_train)\n",
    "clf.get_params_and_results(tx_train, tx_validation, y_train, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a bunch of classifiers, Logistic regression, L2 norm 1. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f89a89aa964b5e0e29a0e1d0886160f39ebbf2130b1a0b091fb1771632a4492"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
